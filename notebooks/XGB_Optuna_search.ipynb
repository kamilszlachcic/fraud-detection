{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-13T14:12:06.410863Z",
     "iopub.status.busy": "2025-03-13T14:12:06.410547Z",
     "iopub.status.idle": "2025-03-13T14:12:08.879109Z",
     "shell.execute_reply": "2025-03-13T14:12:08.878205Z",
     "shell.execute_reply.started": "2025-03-13T14:12:06.410830Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, average_precision_score\n",
    "import gc\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T14:12:13.477372Z",
     "iopub.status.busy": "2025-03-13T14:12:13.477060Z",
     "iopub.status.idle": "2025-03-13T14:12:17.737984Z",
     "shell.execute_reply": "2025-03-13T14:12:17.737024Z",
     "shell.execute_reply.started": "2025-03-13T14:12:13.477344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.1)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->optuna) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T14:12:55.074226Z",
     "iopub.status.busy": "2025-03-13T14:12:55.073898Z",
     "iopub.status.idle": "2025-03-13T14:12:58.904010Z",
     "shell.execute_reply": "2025-03-13T14:12:58.903106Z",
     "shell.execute_reply.started": "2025-03-13T14:12:55.074202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna-integration[xgboost]\n",
      "  Downloading optuna_integration-4.2.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from optuna-integration[xgboost]) (4.2.0)\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from optuna-integration[xgboost]) (2.0.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration[xgboost]) (1.14.1)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration[xgboost]) (6.9.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration[xgboost]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration[xgboost]) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration[xgboost]) (2.0.36)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration[xgboost]) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration[xgboost]) (6.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost->optuna-integration[xgboost]) (1.13.1)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[xgboost]) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[xgboost]) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[xgboost]) (3.1.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->optuna->optuna-integration[xgboost]) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->optuna->optuna-integration[xgboost]) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->optuna->optuna-integration[xgboost]) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->optuna->optuna-integration[xgboost]) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->optuna->optuna-integration[xgboost]) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->optuna->optuna-integration[xgboost]) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration[xgboost]) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna->optuna-integration[xgboost]) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna->optuna-integration[xgboost]) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->optuna->optuna-integration[xgboost]) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->optuna->optuna-integration[xgboost]) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->optuna->optuna-integration[xgboost]) (2024.2.0)\n",
      "Downloading optuna_integration-4.2.1-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: optuna-integration\n",
      "Successfully installed optuna-integration-4.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna-integration[xgboost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T14:13:05.845888Z",
     "iopub.status.busy": "2025-03-13T14:13:05.845415Z",
     "iopub.status.idle": "2025-03-13T14:13:09.238884Z",
     "shell.execute_reply": "2025-03-13T14:13:09.238203Z",
     "shell.execute_reply.started": "2025-03-13T14:13:05.845857Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/input/fraud-detection-procesed-data/XBG_FE_processed_data.pkl\", \"rb\") as f:\n",
    "    data = joblib.load(f)\n",
    "\n",
    "X_train, X_test, y_train, y_test = data[\"X_train\"], data[\"X_test\"], data[\"y_train\"], data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T15:40:18.724785Z",
     "iopub.status.busy": "2025-03-13T15:40:18.724392Z",
     "iopub.status.idle": "2025-03-13T15:40:18.746052Z",
     "shell.execute_reply": "2025-03-13T15:40:18.745312Z",
     "shell.execute_reply.started": "2025-03-13T15:40:18.724744Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Define the paths\n",
    "source_db_path = \"/kaggle/input/optuna-final-db/optuna_fraud_detection_final 135.db\"\n",
    "destination_db_path = \"/kaggle/working/optuna_fraud_detection_final 140.db\"\n",
    "\n",
    "# Copy the database to a writable location\n",
    "shutil.copy(source_db_path, destination_db_path)\n",
    "\n",
    "# ✅ Update Optuna to use the new writable DB path\n",
    "DB_PATH = f\"sqlite:///{destination_db_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T16:30:52.314310Z",
     "iopub.status.busy": "2025-03-13T16:30:52.313945Z",
     "iopub.status.idle": "2025-03-13T16:35:33.109551Z",
     "shell.execute_reply": "2025-03-13T16:35:33.108672Z",
     "shell.execute_reply.started": "2025-03-13T16:30:52.314284Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-03-13 16:30:53,504] Using an existing study with name 'fraud_detection' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Trial 140: Testing Params: {'max_depth': 12, 'learning_rate': 0.027900974155015187, 'subsample': 0.7, 'colsample_bytree': 0.8, 'scale_pos_weight': 62, 'min_child_weight': 8, 'gamma': 0.0003407123923165338, 'reg_alpha': 0.04559318256480473, 'reg_lambda': 8.245848508665857e-05, 'tree_method': 'hist', 'device': 'cuda', 'eval_metric': 'aucpr', 'random_state': 42, 'nthread': -1} | Boost Rounds: 3500\n",
      "[0]\ttrain-aucpr:0.45063+0.01317\ttrain-f1:0.06761+0.00000\ttest-aucpr:0.39870+0.01222\ttest-f1:0.06761+0.00000\n",
      "[100]\ttrain-aucpr:0.82801+0.00163\ttrain-f1:0.39014+0.00258\ttest-aucpr:0.65577+0.01103\ttest-f1:0.33845+0.00502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-13 16:35:33,062] Trial 140 pruned. Trial was pruned at iteration 162.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Hyperparameters: {'max_depth': 12, 'learning_rate': 0.017309377551183877, 'subsample': 0.8, 'colsample_bytree': 0.6, 'scale_pos_weight': 40, 'min_child_weight': 9, 'gamma': 0.0010464167006924024, 'reg_alpha': 0.3487091763789718, 'reg_lambda': 9.441098792689792e-05, 'n_estimators': 2500}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "from optuna.samplers import TPESampler\n",
    "from sqlalchemy import create_engine\n",
    "from optuna.pruners import HyperbandPruner, MedianPruner\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "sampler = TPESampler(multivariate=True, warn_independent_sampling=False)\n",
    "\n",
    "# Load previous trials from SQLite\n",
    "engine = create_engine(DB_PATH.replace(\"sqlite:///\", \"sqlite:///\"))\n",
    "\n",
    "# Create Optuna study with SQLite storage\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=DB_PATH,  # ✅ Store in SQLite\n",
    "    study_name=\"fraud_detection\",\n",
    "    sampler=sampler,\n",
    "    load_if_exists=True  # ✅ Continue previous search if trials exist\n",
    ")\n",
    "#pruner = optuna.pruners.HyperbandPruner()\n",
    "pruner = MedianPruner(n_warmup_steps=150) if study.trials_dataframe().shape[0] < 150 else HyperbandPruner()\n",
    "study.pruner = pruner\n",
    "\n",
    "\n",
    "# Define custom F1-score evaluation function\n",
    "def f1_eval(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred_binary)\n",
    "    return \"f1\", f1\n",
    "\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 11, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.03, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0, step=0.1),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.8, step=0.1),\n",
    "        \"scale_pos_weight\": trial.suggest_int(\"scale_pos_weight\", 40, 90),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 6, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1e-5, 0.005, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-5, 0.95, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-6, 0.4, log=True),\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": \"cuda\",\n",
    "        \"eval_metric\": \"aucpr\",\n",
    "        \"random_state\": 42,\n",
    "        \"nthread\": -1,\n",
    "    }\n",
    "    \n",
    "    # Define number of boosting rounds (dynamic based on trial number)\n",
    "    #if trial.number < 20:\n",
    "    #    num_boost_round = trial.suggest_int(\"n_estimators\", 100, 500, step=50)  # Fewer rounds for early trials\n",
    "    #else:\n",
    "    #    num_boost_round = trial.suggest_int(\"n_estimators\", 1500, 4000, step=500)  # More rounds for fine-tuning\n",
    "\n",
    "    \n",
    "    num_boost_round = trial.suggest_int(\"n_estimators\", 1500, 4000, step=500)\n",
    "    #num_boost_round = trial.suggest_int(\"n_estimators\", 1, 2, step=1)\n",
    "\n",
    "    print(f\"🔍 Trial {trial.number}: Testing Params: {params} | Boost Rounds: {num_boost_round}\")\n",
    "\n",
    "    # Convert dataset into DMatrix (XGBoost format)\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "    # Set up pruning callback\n",
    "    pruning_callback = XGBoostPruningCallback(trial, \"test-aucpr\")\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=5,\n",
    "        custom_metric=f1_eval,  # ✅ Also track F1-score\n",
    "        maximize=True,  # ✅ Optimize both AUC-PR & F1\n",
    "        stratified=True,\n",
    "        seed=42,\n",
    "        verbose_eval=100,\n",
    "        callbacks=[pruning_callback],\n",
    "    )\n",
    "\n",
    "    # Get best results\n",
    "    best_aucpr = cv_results[\"test-aucpr-mean\"].max()\n",
    "    best_f1 = cv_results[\"test-f1-mean\"].max() \n",
    "    final_score = (best_aucpr + best_f1) / 2  # Optimize both metrics\n",
    "\n",
    "    print(f\"🔥 Best AUC-PR: {best_aucpr:.4f}, Best F1: {best_f1:.4f}, Final Score: {final_score: .4f}\")\n",
    "\n",
    "    # ✅ Save to SQLite\n",
    "    trial_results = pd.DataFrame([{\n",
    "        \"Trial\": trial.number,\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"learning_rate\": params[\"learning_rate\"],\n",
    "        \"subsample\": params[\"subsample\"],\n",
    "        \"colsample_bytree\": params[\"colsample_bytree\"],\n",
    "        \"scale_pos_weight\": params[\"scale_pos_weight\"],\n",
    "        \"min_child_weight\": params[\"min_child_weight\"],\n",
    "        \"gamma\": params[\"gamma\"],\n",
    "        \"reg_alpha\": params[\"reg_alpha\"],\n",
    "        \"reg_lambda\": params[\"reg_lambda\"],\n",
    "        \"Boost Rounds\": num_boost_round,\n",
    "        \"Best AUC-PR\": best_aucpr,\n",
    "        \"Best F1\": best_f1,\n",
    "        \"Final Score\": final_score\n",
    "    }])\n",
    "\n",
    "\n",
    "    return final_score \n",
    "\n",
    "# Run Optuna optimization\n",
    "\n",
    "study.optimize(objective, n_trials=140)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"✅ Best Hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T16:36:45.157962Z",
     "iopub.status.busy": "2025-03-13T16:36:45.157659Z",
     "iopub.status.idle": "2025-03-13T16:36:45.210004Z",
     "shell.execute_reply": "2025-03-13T16:36:45.209077Z",
     "shell.execute_reply.started": "2025-03-13T16:36:45.157941Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"optuna_best_params.pkl\", \"wb\") as f:\n",
    "    pickle.dump(study.best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T16:36:47.512187Z",
     "iopub.status.busy": "2025-03-13T16:36:47.511906Z",
     "iopub.status.idle": "2025-03-13T16:51:39.101963Z",
     "shell.execute_reply": "2025-03-13T16:51:39.101007Z",
     "shell.execute_reply.started": "2025-03-13T16:36:47.512166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.86775\n",
      "[100]\tvalidation_0-logloss:0.36906\n",
      "[200]\tvalidation_0-logloss:0.25500\n",
      "[300]\tvalidation_0-logloss:0.21329\n",
      "[400]\tvalidation_0-logloss:0.17912\n",
      "[500]\tvalidation_0-logloss:0.15346\n",
      "[600]\tvalidation_0-logloss:0.13170\n",
      "[700]\tvalidation_0-logloss:0.11432\n",
      "[800]\tvalidation_0-logloss:0.10164\n",
      "[900]\tvalidation_0-logloss:0.09114\n",
      "[1000]\tvalidation_0-logloss:0.08299\n",
      "[1100]\tvalidation_0-logloss:0.07561\n",
      "[1200]\tvalidation_0-logloss:0.06959\n",
      "[1300]\tvalidation_0-logloss:0.06475\n",
      "[1400]\tvalidation_0-logloss:0.06047\n",
      "[1500]\tvalidation_0-logloss:0.05711\n",
      "[1600]\tvalidation_0-logloss:0.05424\n",
      "[1700]\tvalidation_0-logloss:0.05202\n",
      "[1800]\tvalidation_0-logloss:0.04990\n",
      "[1900]\tvalidation_0-logloss:0.04805\n",
      "[2000]\tvalidation_0-logloss:0.04663\n",
      "[2100]\tvalidation_0-logloss:0.04534\n",
      "[2200]\tvalidation_0-logloss:0.04429\n",
      "[2300]\tvalidation_0-logloss:0.04333\n",
      "[2400]\tvalidation_0-logloss:0.04258\n",
      "[2499]\tvalidation_0-logloss:0.04196\n",
      "✅ XGBoost training complete!\n"
     ]
    }
   ],
   "source": [
    "# ✅ Train Final Model Using Best Iteration\n",
    "xgb_model = xgb.XGBClassifier(**study.best_params)\n",
    "\n",
    "# ✅ Fit Model with Verbose\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=100,\n",
    ")\n",
    "\n",
    "print(\"✅ XGBoost training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T17:26:40.969432Z",
     "iopub.status.busy": "2025-03-13T17:26:40.969105Z",
     "iopub.status.idle": "2025-03-13T17:27:29.247713Z",
     "shell.execute_reply": "2025-03-13T17:27:29.246755Z",
     "shell.execute_reply.started": "2025-03-13T17:26:40.969409Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibrating Model: 100%|██████████| 1/1 [00:38<00:00, 38.99s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Calibration complete!\n",
      "✅ Applied Post-Training Calibration!\n"
     ]
    }
   ],
   "source": [
    "# Apply probability calibration\n",
    "calibrator = CalibratedClassifierCV(xgb_model, method=\"sigmoid\", cv=\"prefit\")\n",
    "with tqdm(total=1, desc=\"Calibrating Model\", unit=\"step\") as pbar:\n",
    "    calibrator.fit(X_train, y_train)  # Train the calibration model\n",
    "    pbar.update(1)  # Update progress after fit()\n",
    "\n",
    "print(\"✅ Calibration complete!\")\n",
    "\n",
    "# Get calibrated probabilities\n",
    "y_proba_calibrated = calibrator.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"✅ Applied Post-Training Calibration!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T17:27:45.338275Z",
     "iopub.status.busy": "2025-03-13T17:27:45.337964Z",
     "iopub.status.idle": "2025-03-13T17:27:45.585659Z",
     "shell.execute_reply": "2025-03-13T17:27:45.584939Z",
     "shell.execute_reply.started": "2025-03-13T17:27:45.338253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Model Evaluation:\n",
      "🔹 ROC-AUC: 0.9762\n",
      "🔹 Precision: 0.9616\n",
      "🔹 Recall: 0.7026\n",
      "🔹 F1 Score: 0.8120\n",
      "📌 Precision-Recall AUC: 0.8784\n"
     ]
    }
   ],
   "source": [
    "# Get predictions using threshold 0.4 (adjust if needed)\n",
    "optimal_threshold = 0.15\n",
    "y_pred_adjusted = (y_proba_calibrated > optimal_threshold).astype(int)\n",
    "\n",
    "# Compute Metrics\n",
    "roc_auc = roc_auc_score(y_test, y_proba_calibrated)\n",
    "pr_auc = average_precision_score(y_test, y_proba_calibrated)\n",
    "f1 = f1_score(y_test, y_pred_adjusted)\n",
    "precision = precision_score(y_test, y_pred_adjusted)\n",
    "recall = recall_score(y_test, y_pred_adjusted)\n",
    "\n",
    "# Print Results\n",
    "print(f\"📊 Model Evaluation:\")\n",
    "print(f\"🔹 ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"🔹 Precision: {precision:.4f}\")\n",
    "print(f\"🔹 Recall: {recall:.4f}\")\n",
    "print(f\"🔹 F1 Score: {f1:.4f}\")\n",
    "print(f\"📌 Precision-Recall AUC: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T17:27:49.495263Z",
     "iopub.status.busy": "2025-03-13T17:27:49.494948Z",
     "iopub.status.idle": "2025-03-13T17:27:49.973970Z",
     "shell.execute_reply": "2025-03-13T17:27:49.973194Z",
     "shell.execute_reply.started": "2025-03-13T17:27:49.495235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved!\n"
     ]
    }
   ],
   "source": [
    "save_dict = {\n",
    "    \"model\": xgb_model,  # Trained XGBoost model\n",
    "    \"calibrator\": calibrator,  # ✅ Save the probability calibrator\n",
    "    \"feature_names\": X_train.columns.tolist(),  # Ensures correct input order\n",
    "}\n",
    "\n",
    "with open(\"xgb_fraud_detection_Malwi_GPU_Kaggle_13_03.pkl\", \"wb\") as f:\n",
    "    pickle.dump(save_dict, f)\n",
    "\n",
    "print(\"✅ Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6706956,
     "sourceId": 10805395,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6713051,
     "sourceId": 10813398,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6713962,
     "sourceId": 11021140,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
